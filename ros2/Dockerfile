# ============================================================================
# ROS2 Stage
# ============================================================================
FROM osrf/ros:humble-desktop-full AS base

ENV DEBIAN_FRONTEND=noninteractive

# Add Intel RealSense repository
RUN apt-get update && apt-get install -y --no-install-recommends \
    apt-transport-https \
    ca-certificates \
    curl \
    gnupg \
    && mkdir -p /etc/apt/keyrings \
    && curl -sSf https://librealsense.intel.com/Debian/librealsense.pgp | tee /etc/apt/keyrings/librealsense.pgp > /dev/null \
    && echo "deb [signed-by=/etc/apt/keyrings/librealsense.pgp] https://librealsense.intel.com/Debian/apt-repo $(lsb_release -cs) main" | tee /etc/apt/sources.list.d/librealsense.list \
    && apt-get update \
    && rm -rf /var/lib/apt/lists/*

# Install system dependencies in single layer
RUN apt-get update && apt-get install -y --no-install-recommends \
    xserver-xorg \
    ros-humble-moveit \
    ros-humble-realsense2-camera \
    ros-humble-realsense2-description \
    librealsense2 \
    librealsense2-utils \
    librealsense2-dev \
    v4l-utils \
    python3-pip \
    python3-opencv \
    sudo \
    espeak-ng \
    alsa-utils \
    pulseaudio-utils \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies with fixed versions
RUN pip3 install --no-cache-dir \
    tensorflow==2.15.1 \
    "numpy<2"

# Install ROS dependencies with caching optimization
# Copy only package.xml files first for better layer caching
ENV ROS2_DEPENDENCIES_DIR=/tmp/ros2_dependencies

# Copy all package.xml files while preserving directory structure
# This uses a shell script to find and copy package.xml files automatically
COPY ros2/src ${ROS2_DEPENDENCIES_DIR}/src
RUN find ${ROS2_DEPENDENCIES_DIR}/src -type f ! -name "package.xml" -delete && \
    find ${ROS2_DEPENDENCIES_DIR}/src -type d -empty -delete

# Install dependencies based on package.xml files
RUN apt-get update && \
    rosdep install -r -y -i --from-paths ${ROS2_DEPENDENCIES_DIR} && \
    rm -rf ${ROS2_DEPENDENCIES_DIR} && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /workspace/ros2

# Create a user that matches host user (UID/GID will be passed at build time)
ARG USER_ID=1000
ARG GROUP_ID=1000
ARG USERNAME=ros2

RUN groupadd -g ${GROUP_ID} ${USERNAME} || true && \
    useradd -l -u ${USER_ID} -g ${GROUP_ID} -m -s /bin/bash ${USERNAME} && \
    usermod -aG sudo ${USERNAME} && \
    echo "${USERNAME} ALL=(ALL) NOPASSWD:ALL" >> /etc/sudoers

# Set ownership of workspace
RUN mkdir -p /workspace/ros2 && chown -R ${USER_ID}:${GROUP_ID} /workspace

USER ${USERNAME}

FROM base AS dev

# Need to re-declare ARGs from base stage for use in dev stage
ARG USER_ID=1000
ARG GROUP_ID=1000
ARG USERNAME=ros2

# Switch back to root to install additional packages
USER root

RUN apt-get update && apt-get install -y --no-install-recommends \
    vim \
    tmux \
    iproute2 \
    x11-apps \
    && rm -rf /var/lib/apt/lists/*

# Switch back to the non-root user
USER ${USERNAME}

CMD ["/bin/bash"]

# ============================================================================
# VLA Fine-tuning Stage
# ============================================================================
FROM nvidia/cuda:13.0.1-devel-ubuntu22.04 AS vla

ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1

# Install Python and system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3.10 \
    python3-pip \
    git \
    wget \
    curl \
    build-essential \
    ninja-build \
    && rm -rf /var/lib/apt/lists/*

# Upgrade pip
RUN pip3 install --no-cache-dir --upgrade pip setuptools wheel

# Install PyTorch with CUDA 12.4 support
RUN pip3 install --no-cache-dir \
    torch==2.3.1 \
    torchvision==0.18.1 \
    torchaudio==2.3.1 \
    --index-url https://download.pytorch.org/whl/cu124

# Install VLA fine-tuning requirements
COPY vla/requirements.txt /tmp/vla_requirements.txt
RUN pip3 install --no-cache-dir -r /tmp/vla_requirements.txt

# Install Flash Attention 2 (OPTIONAL - for faster training)
# This can take 5-10 minutes to compile and requires compatible GPU
# If installation fails, training will fall back to standard attention mechanism
RUN pip3 install --no-cache-dir packaging ninja && \
    (pip3 install --no-cache-dir flash-attn==2.5.5 --no-build-isolation && \
     echo "Flash Attention 2 installed successfully") || \
    (echo "WARNING: Flash Attention 2 installation failed - training will use standard attention" && \
     echo "This is expected on non-NVIDIA GPUs or incompatible CUDA versions")

# Set up workspace
WORKDIR /workspace

# Copy VLA fine-tuning scripts
COPY vla/ /workspace/vla/

# Set Python path
ENV PYTHONPATH=/workspace:$PYTHONPATH

# Default command
CMD ["/bin/bash"]

