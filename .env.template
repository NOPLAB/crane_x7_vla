# ============================================================================
# CRANE-X7 環境設定テンプレート
# ============================================================================
# このファイルを .env にコピーして、環境に合わせて値をカスタマイズしてください
#
# 使い方:
#   cp .env.template .env
#   # .env を編集して設定を変更
#   docker compose --profile <プロファイル名> up
# ============================================================================

# ----------------------------------------------------------------------------
# ディスプレイ設定
# ----------------------------------------------------------------------------
# GUIアプリケーション（RViz、Gazebo）用のX11ディスプレイ
# WSL2の場合: :0 を使用
# ネイティブLinuxの場合: ディスプレイに応じて :0 または :1 を使用
DISPLAY=:0

# ----------------------------------------------------------------------------
# ROS 2 設定
# ----------------------------------------------------------------------------
# DDS通信用のROS 2 Domain ID
# 複数マシンでテレオペレーションする場合は、すべてのマシンで同じ値を使用
# 有効範囲: 0-101 (デフォルト: 42)
ROS_DOMAIN_ID=42

# ----------------------------------------------------------------------------
# USBデバイス設定
# ----------------------------------------------------------------------------
# 実機ロボット制御用のUSBデバイス
# 利用可能なデバイスを確認: ls -l /dev/ttyUSB*
USB_DEVICE=/dev/ttyUSB0

# Followerロボット用のUSBデバイス（2台のロボットでテレオペレーションする場合）
# teleop, teleop-viewer プロファイルで使用
USB_DEVICE_FOLLOWER=/dev/ttyUSB1

# ----------------------------------------------------------------------------
# カメラ設定
# ----------------------------------------------------------------------------
# Intel RealSense D435 カメラのシリアル番号
# シリアル番号の確認方法: rs-enumerate-devices | grep "Serial Number"
# 未指定の場合は最初に検出されたカメラを使用
CAMERA_SERIAL=

# 2台目のカメラシリアル番号（マルチカメラ構成の場合）
CAMERA2_SERIAL=

# RealSense D435 を使用するかどうか
# true: D435カメラを使用
# false: カメラなしで動作
# デフォルト: false
USE_D435=false

# RViz ビューアを表示するかどうか
# true: RVizでロボットの状態を可視化
# false: ヘッドレスモード
# デフォルト: false
USE_VIEWER=false

# ----------------------------------------------------------------------------
# Gemini API設定
# ----------------------------------------------------------------------------
# Google Gemini Robotics-ER APIキー
# 取得方法: https://ai.google.dev/gemini-api/docs
# gemini, gemini-sim プロファイルで使用
GEMINI_API_KEY=

# ----------------------------------------------------------------------------
# VLA (Vision-Language-Action) 設定
# ----------------------------------------------------------------------------
# Hugging Face トークン（モデルダウンロード用）
# 取得方法: https://huggingface.co/settings/tokens
# vla, vla-sim, maniskill-vla プロファイルで使用
HF_TOKEN=

# Hugging Face キャッシュディレクトリ（ホスト側パス）
# モデルをキャッシュしてコンテナ再起動時の再ダウンロードを防止
# デフォルト: $HOME/.cache/huggingface
# HF_CACHE_DIR=/home/youruser/.cache/huggingface

# VLAモデルパス（必須）
# ファインチューニング済みモデルのパスを指定
# 例: /workspace/vla/outputs/<model_dir>/checkpoint-1500
VLA_MODEL_PATH=

# VLAタスク指示（自然言語）
# ロボットに実行させるタスクを自然言語で指定
# 例: "pick up the red block", "move the cup to the left"
# デフォルト: pick up the object
VLA_TASK_INSTRUCTION=

# VLA推論デバイス
# cuda: GPU使用（推奨）
# cpu: CPU使用（遅いが、GPU不要）
# デフォルト: cuda
VLA_DEVICE=cuda

# ----------------------------------------------------------------------------
# Lift シミュレーション設定（統一シミュレータ抽象化）
# ----------------------------------------------------------------------------
# シミュレータ選択
# maniskill: ManiSkill 3.0ベース（安定、推奨）
# genesis: Genesis 0.3.x ベース（高速、GPU推奨）
# デフォルト: maniskill
LIFT_SIMULATOR=maniskill

# シミュレーションバックエンド
# gpu: GPU使用（高速、レンダリング可能）
# cpu: CPU使用（GPUなし環境用）
# デフォルト: cpu
LIFT_BACKEND=cpu

# レンダリングモード
# rgb_array: 画像観測を取得（GPU必須）
# human: GUIウィンドウ表示（GPU必須）
# none: レンダリングなし（CPU可）
# デフォルト: none
LIFT_RENDER_MODE=none

# ----------------------------------------------------------------------------
# Tailscale VPN設定（リモートVLA推論用）
# ----------------------------------------------------------------------------
# リモートGPUサーバー（Vast.ai/Runpod）と通信するためのVPN設定

# Tailscale認証キー（リモートVLA推論時に必須）
# 取得方法: https://login.tailscale.com/admin/settings/keys
# - "Generate auth key" をクリック
# - Reusable: ON（複数デバイスで使用する場合）
# - Ephemeral: ON（推奨 - コンテナ終了時に自動削除）
TS_AUTHKEY=

# Tailscale userspace networking モード
# true: /dev/net/tun なしで動作（制限環境用）
# false: 通常のTUNデバイスを使用（ローカル側、推奨）
# デフォルト: false
TS_USERSPACE=false

# Tailscaleホスト名（リモート推論サーバー側）
# MagicDNS名としてTailnetworkで使用
# デフォルト: crane-x7-inference
TS_HOSTNAME=crane-x7-inference

# ----------------------------------------------------------------------------
# rosbridge設定（WebSocket経由のリモート推論）
# ----------------------------------------------------------------------------
# rosbridge_serverのWebSocketポート
# リモートGPUサーバーからこのポートに接続します
# デフォルト: 9090
ROSBRIDGE_PORT=9090

# rosbridgeホスト名（ローカルロボット側のTailscale MagicDNS名）
# リモート推論サーバーからこの名前で接続
# デフォルト: crane-x7-local
ROSBRIDGE_HOST=crane-x7-local

# VLA推論レート (Hz)
# リモート推論サービスで使用
# デフォルト: 10.0
VLA_INFERENCE_RATE=10.0

# ----------------------------------------------------------------------------
# コンテナユーザー設定
# ----------------------------------------------------------------------------
# コンテナ内のホームディレクトリ名として使用
# HF_HOMEのパス（/home/${USERNAME}/.cache/huggingface）に影響
# デフォルト: ros2
USERNAME=ros2

# ----------------------------------------------------------------------------
# LeRobot設定
# ----------------------------------------------------------------------------
# LeRobotポリシーのパス（推論時に使用）
# 学習済みポリシーのディレクトリを指定
# 例: outputs/act_crane_x7/checkpoint_final
LEROBOT_POLICY_PATH=

# ----------------------------------------------------------------------------
# Weights & Biases設定（トレーニング用）
# ----------------------------------------------------------------------------
# W&B APIキー（トレーニングログ用）
# 取得方法: https://wandb.ai/settings
# vlarl, lerobot-train プロファイルで使用
WANDB_API_KEY=
